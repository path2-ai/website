# Model feedback

If you trained a model and want to feedback its predictions into refinery, e.g. to find records where your weakly supervised label didn't match the model prediction, you can now do so easily.

![](https://files.readme.io/84ce5fb-model-callbacks.png)

To collect this feedback, simply use our [Python SDK](doc:python-sdk). There are multiple wrappers for e.g. HuggingFace, PyTorch or Sklearn.

You can use these feedback loops to find e.g. _hard wrong model predictions_. These are cases, in which your model confidently predicts something, but the weakly supervised label says something different.

![](https://files.readme.io/614d713-hard-wrong-predictions.png)

> ðŸš§ Currently only available for classification models
>
> We're testing this feature on classification models for now. If it is widely used, we'll soon add a callback for extraction models.
